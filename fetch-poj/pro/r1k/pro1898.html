<h2 align="center">Entropy</h2></div>
<div class="plm"><table align="center"><tr><td><b>Time Limit:</b> 1000MS</td><td width="10px"></td><td colspan="3"><b>Memory Limit:</b> 30000K</td></tr><tr><td><b>Total Submissions:</b> 889</td><td width="10px"></td><td><b>Accepted:</b> 212</td><td width="10px"></td><td style="font-weight:bold; color:red;">Special Judge</td></tr></table></div><h3>Description</h3><div class="ptx" lang="en-US">In 1948 Claude E. Shannon in "The Mathematical Theory of Communication"' has introduced his famous formula for the entropy of a discrete set of probabilities p1, ... , p<sub>n</sub>: <br><center><pre><font size=5>H=-&sum;p<sub>i</sub>log<sub>2</sub>p<sub>i</sub></font></pre></center><br>We will apply this formula to an arbitrary text string by letting p<sub>i</sub> be the relative frequencies of occurrence of characters in the string. For example, the entropy of the string "Northeastern European Regional Contest" with the length of 38 characters (including 3 spaces) is 3.883 with 3 digits after decimal point. The following table shows relative frequencies and the corresponding summands for the entropy of this string.<br><center><img src=images/1898_1.jpg></center><br>Your task is to find a string with the given entropy.  </div><h3>Input</h3><div class="ptx" lang="en-US">The input consists of a single real number H (0.00 <= H <= 6.00) with 2 digits after decimal point. </div><h3>Output</h3><div class="ptx" lang="en-US">Write to the output file a line with a single string of at least one and up to 1000 characters '0'-'9', 'a'-'z', 'A'-'Z', '.' (dot), and spaces. This string must have the entropy within 0.005 of H. </div><h3>Sample Input</h3><pre class="sio">3.88
</pre><h3>Sample Output</h3><pre class="sio">Northeastern European Regional Contest
</pre><h3>Source</h3><div class="ptx" lang="en-US"><a>Northeastern Europe 2003</a></div></td></tr></table>
